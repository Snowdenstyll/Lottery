{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Snowdenstyll/Lottery/blob/main/server/jupyterNotebooks/Keno_Lottery_Claude.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Input\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Data Preprocessing\n",
        "def prepare_data(csv_file):\n",
        "    # Read the data\n",
        "    df = pd.read_csv(csv_file)\n",
        "\n",
        "    # Separate A and P games\n",
        "    df_A = df[df['AP'] == 'A'].drop(['PlayDate', 'AP'], axis=1)\n",
        "    df_P = df[df['AP'] == 'P'].drop(['PlayDate', 'AP'], axis=1)\n",
        "\n",
        "    # Process each game type separately\n",
        "    def process_game_data(game_df):\n",
        "        # Convert to float\n",
        "        game_df = game_df.astype(float)\n",
        "\n",
        "        # Normalize numbers to [0,1] range\n",
        "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "        transformed_data = scaler.fit_transform(game_df.values)\n",
        "        transformed_df = pd.DataFrame(data=transformed_data, columns=game_df.columns)\n",
        "\n",
        "        # Create sequences\n",
        "        number_of_rows = len(transformed_df)\n",
        "        window_length = 5\n",
        "        number_of_features = transformed_df.shape[1]\n",
        "\n",
        "        X = np.empty([number_of_rows - window_length, window_length, number_of_features], dtype=float)\n",
        "        y = np.empty([number_of_rows - window_length, number_of_features], dtype=float)\n",
        "\n",
        "        for i in range(0, number_of_rows - window_length):\n",
        "            X[i] = transformed_df.iloc[i:i+window_length, :]\n",
        "            y[i] = transformed_df.iloc[i+window_length:i+window_length+1, :].values\n",
        "\n",
        "        return X, y, scaler\n",
        "\n",
        "    return process_game_data(df_A), process_game_data(df_P)\n",
        "\n",
        "# Create the model\n",
        "def create_model(window_length, number_of_features):\n",
        "    model = Sequential([\n",
        "        Input(shape=(window_length, number_of_features)),  # Explicit input layer\n",
        "        Bidirectional(LSTM(128, return_sequences=True)),\n",
        "        Dropout(0.3),\n",
        "        Bidirectional(LSTM(64)),\n",
        "        Dropout(0.3),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(number_of_features, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                 loss='mse',\n",
        "                 metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "# Train separate models for A and P games\n",
        "def train_model(X, y, game_type):\n",
        "    try:\n",
        "        # Split the data\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Create and train the model\n",
        "        model = create_model(X.shape[1], X.shape[2])\n",
        "\n",
        "        callbacks = [\n",
        "            EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True),\n",
        "            ModelCheckpoint(f'best_model_{game_type}.keras',  # Changed extension to .keras\n",
        "                          save_best_only=True,\n",
        "                          monitor='val_loss')\n",
        "        ]\n",
        "\n",
        "        history = model.fit(X_train, y_train,\n",
        "                          epochs=200,\n",
        "                          batch_size=32,\n",
        "                          validation_split=0.2,\n",
        "                          callbacks=callbacks,\n",
        "                          verbose=1)\n",
        "\n",
        "        return model, history\n",
        "    except Exception as e:\n",
        "        print(f\"Error training model for game type {game_type}: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "# Function to convert predictions back to actual numbers\n",
        "def process_predictions(predictions, scaler, original_features_count=20):\n",
        "    try:\n",
        "        # Inverse transform the normalized predictions\n",
        "        predictions_original = scaler.inverse_transform(predictions)\n",
        "\n",
        "        # Round to nearest integers and ensure unique numbers\n",
        "        rounded_predictions = []\n",
        "        for pred in predictions_original:\n",
        "            # Sort numbers and round them\n",
        "            sorted_numbers = np.sort(np.round(pred))\n",
        "            # Ensure no duplicates and numbers are within range\n",
        "            unique_numbers = np.unique(np.clip(sorted_numbers, 1, 69))\n",
        "            # If we don't have exactly 20 numbers, adjust\n",
        "            while len(unique_numbers) < original_features_count:\n",
        "                # Add missing numbers\n",
        "                available_numbers = set(range(1, 70)) - set(unique_numbers)\n",
        "                unique_numbers = np.append(unique_numbers, np.random.choice(list(available_numbers)))\n",
        "                unique_numbers = np.sort(unique_numbers)\n",
        "            rounded_predictions.append(unique_numbers[:20])\n",
        "\n",
        "        return rounded_predictions\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing predictions: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # Process both game types\n",
        "        print(\"Processing data...\")\n",
        "        (X_A, y_A, scaler_A), (X_P, y_P, scaler_P) = prepare_data(\"2024.csv\")\n",
        "\n",
        "        print(\"Training model A...\")\n",
        "        # Train models for both game types\n",
        "        model_A, history_A = train_model(X_A, y_A, 'A')\n",
        "\n",
        "        print(\"Training model P...\")\n",
        "        model_P, history_P = train_model(X_P, y_P, 'P')\n",
        "\n",
        "        # Make predictions for next games\n",
        "        print(\"Making predictions...\")\n",
        "        last_sequence_A = X_A[-1:]\n",
        "        last_sequence_P = X_P[-1:]\n",
        "\n",
        "        pred_A = model_A.predict(last_sequence_A)\n",
        "        pred_P = model_P.predict(last_sequence_P)\n",
        "\n",
        "        # Convert predictions to actual numbers\n",
        "        numbers_A = process_predictions(pred_A, scaler_A)\n",
        "        numbers_P = process_predictions(pred_P, scaler_P)\n",
        "\n",
        "        print(\"\\nPredicted numbers for next 'A' game:\", numbers_A[0])\n",
        "        print(\"Predicted numbers for next 'P' game:\", numbers_P[0])\n",
        "\n",
        "        # Evaluate models\n",
        "        print(\"\\nModel A Evaluation:\")\n",
        "        loss_A = model_A.evaluate(X_A, y_A)\n",
        "        print(f\"MSE: {loss_A[0]:.4f}, MAE: {loss_A[1]:.4f}\")\n",
        "\n",
        "        print(\"\\nModel P Evaluation:\")\n",
        "        loss_P = model_P.evaluate(X_P, y_P)\n",
        "        print(f\"MSE: {loss_P[0]:.4f}, MAE: {loss_P[1]:.4f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {str(e)}\")"
      ],
      "metadata": {
        "id": "BphE_sXjahe9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "9d88897f-b1f8-43e7-a572-6c1716782b69"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing data...\n",
            "Training model A...\n",
            "Epoch 1/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - loss: 0.0608 - mae: 0.2062 - val_loss: 0.0496 - val_mae: 0.1849\n",
            "Epoch 2/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0366 - mae: 0.1558 - val_loss: 0.0475 - val_mae: 0.1605\n",
            "Epoch 3/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0345 - mae: 0.1451 - val_loss: 0.0440 - val_mae: 0.1609\n",
            "Epoch 4/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0354 - mae: 0.1506 - val_loss: 0.0441 - val_mae: 0.1658\n",
            "Epoch 5/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0332 - mae: 0.1473 - val_loss: 0.0436 - val_mae: 0.1594\n",
            "Epoch 6/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0356 - mae: 0.1486 - val_loss: 0.0436 - val_mae: 0.1587\n",
            "Epoch 7/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0343 - mae: 0.1469 - val_loss: 0.0434 - val_mae: 0.1598\n",
            "Epoch 8/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0326 - mae: 0.1447 - val_loss: 0.0433 - val_mae: 0.1611\n",
            "Epoch 9/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0313 - mae: 0.1425 - val_loss: 0.0434 - val_mae: 0.1593\n",
            "Epoch 10/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0334 - mae: 0.1459 - val_loss: 0.0435 - val_mae: 0.1606\n",
            "Epoch 11/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0318 - mae: 0.1407 - val_loss: 0.0438 - val_mae: 0.1588\n",
            "Epoch 12/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0321 - mae: 0.1426 - val_loss: 0.0434 - val_mae: 0.1604\n",
            "Epoch 13/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0318 - mae: 0.1419 - val_loss: 0.0435 - val_mae: 0.1600\n",
            "Epoch 14/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0333 - mae: 0.1463 - val_loss: 0.0434 - val_mae: 0.1594\n",
            "Epoch 15/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0306 - mae: 0.1400 - val_loss: 0.0435 - val_mae: 0.1586\n",
            "Epoch 16/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0333 - mae: 0.1455 - val_loss: 0.0434 - val_mae: 0.1603\n",
            "Epoch 17/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0306 - mae: 0.1386 - val_loss: 0.0436 - val_mae: 0.1594\n",
            "Epoch 18/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0324 - mae: 0.1423 - val_loss: 0.0435 - val_mae: 0.1596\n",
            "Epoch 19/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0314 - mae: 0.1419 - val_loss: 0.0434 - val_mae: 0.1616\n",
            "Epoch 20/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0318 - mae: 0.1420 - val_loss: 0.0437 - val_mae: 0.1585\n",
            "Epoch 21/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0300 - mae: 0.1380 - val_loss: 0.0436 - val_mae: 0.1587\n",
            "Epoch 22/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0308 - mae: 0.1392 - val_loss: 0.0435 - val_mae: 0.1603\n",
            "Epoch 23/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0307 - mae: 0.1395 - val_loss: 0.0437 - val_mae: 0.1587\n",
            "Epoch 24/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0320 - mae: 0.1411 - val_loss: 0.0436 - val_mae: 0.1600\n",
            "Epoch 25/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0310 - mae: 0.1392 - val_loss: 0.0436 - val_mae: 0.1588\n",
            "Epoch 26/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0311 - mae: 0.1403 - val_loss: 0.0435 - val_mae: 0.1594\n",
            "Epoch 27/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0319 - mae: 0.1397 - val_loss: 0.0441 - val_mae: 0.1581\n",
            "Epoch 28/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0328 - mae: 0.1435 - val_loss: 0.0434 - val_mae: 0.1597\n",
            "Training model P...\n",
            "Epoch 1/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 108ms/step - loss: 0.0607 - mae: 0.2071 - val_loss: 0.0561 - val_mae: 0.1989\n",
            "Epoch 2/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0422 - mae: 0.1679 - val_loss: 0.0499 - val_mae: 0.1710\n",
            "Epoch 3/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0377 - mae: 0.1510 - val_loss: 0.0488 - val_mae: 0.1738\n",
            "Epoch 4/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0376 - mae: 0.1547 - val_loss: 0.0484 - val_mae: 0.1770\n",
            "Epoch 5/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0340 - mae: 0.1490 - val_loss: 0.0479 - val_mae: 0.1725\n",
            "Epoch 6/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0356 - mae: 0.1499 - val_loss: 0.0478 - val_mae: 0.1712\n",
            "Epoch 7/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0337 - mae: 0.1466 - val_loss: 0.0481 - val_mae: 0.1735\n",
            "Epoch 8/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0334 - mae: 0.1454 - val_loss: 0.0479 - val_mae: 0.1728\n",
            "Epoch 9/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0353 - mae: 0.1501 - val_loss: 0.0479 - val_mae: 0.1717\n",
            "Epoch 10/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0334 - mae: 0.1448 - val_loss: 0.0481 - val_mae: 0.1714\n",
            "Epoch 11/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0343 - mae: 0.1463 - val_loss: 0.0481 - val_mae: 0.1740\n",
            "Epoch 12/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0342 - mae: 0.1477 - val_loss: 0.0482 - val_mae: 0.1708\n",
            "Epoch 13/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0351 - mae: 0.1491 - val_loss: 0.0482 - val_mae: 0.1721\n",
            "Epoch 14/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0328 - mae: 0.1441 - val_loss: 0.0480 - val_mae: 0.1722\n",
            "Epoch 15/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0339 - mae: 0.1461 - val_loss: 0.0477 - val_mae: 0.1720\n",
            "Epoch 16/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0356 - mae: 0.1501 - val_loss: 0.0483 - val_mae: 0.1724\n",
            "Epoch 17/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0334 - mae: 0.1449 - val_loss: 0.0477 - val_mae: 0.1713\n",
            "Epoch 18/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0339 - mae: 0.1478 - val_loss: 0.0482 - val_mae: 0.1738\n",
            "Epoch 19/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0352 - mae: 0.1497 - val_loss: 0.0479 - val_mae: 0.1714\n",
            "Epoch 20/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0322 - mae: 0.1429 - val_loss: 0.0478 - val_mae: 0.1709\n",
            "Epoch 21/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0329 - mae: 0.1432 - val_loss: 0.0481 - val_mae: 0.1722\n",
            "Epoch 22/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0342 - mae: 0.1478 - val_loss: 0.0477 - val_mae: 0.1712\n",
            "Epoch 23/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0342 - mae: 0.1474 - val_loss: 0.0477 - val_mae: 0.1704\n",
            "Epoch 24/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0345 - mae: 0.1460 - val_loss: 0.0479 - val_mae: 0.1738\n",
            "Epoch 25/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0338 - mae: 0.1472 - val_loss: 0.0486 - val_mae: 0.1708\n",
            "Epoch 26/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0338 - mae: 0.1453 - val_loss: 0.0482 - val_mae: 0.1730\n",
            "Epoch 27/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0332 - mae: 0.1455 - val_loss: 0.0482 - val_mae: 0.1713\n",
            "Epoch 28/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0318 - mae: 0.1396 - val_loss: 0.0482 - val_mae: 0.1725\n",
            "Epoch 29/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0328 - mae: 0.1442 - val_loss: 0.0487 - val_mae: 0.1722\n",
            "Epoch 30/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0316 - mae: 0.1416 - val_loss: 0.0475 - val_mae: 0.1720\n",
            "Epoch 31/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0331 - mae: 0.1458 - val_loss: 0.0484 - val_mae: 0.1735\n",
            "Epoch 32/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0316 - mae: 0.1413 - val_loss: 0.0481 - val_mae: 0.1713\n",
            "Epoch 33/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0347 - mae: 0.1481 - val_loss: 0.0501 - val_mae: 0.1760\n",
            "Epoch 34/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0339 - mae: 0.1461 - val_loss: 0.0475 - val_mae: 0.1704\n",
            "Epoch 35/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0312 - mae: 0.1399 - val_loss: 0.0489 - val_mae: 0.1736\n",
            "Epoch 36/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0339 - mae: 0.1464 - val_loss: 0.0486 - val_mae: 0.1729\n",
            "Epoch 37/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0302 - mae: 0.1374 - val_loss: 0.0477 - val_mae: 0.1716\n",
            "Epoch 38/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0330 - mae: 0.1440 - val_loss: 0.0487 - val_mae: 0.1731\n",
            "Epoch 39/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0340 - mae: 0.1471 - val_loss: 0.0498 - val_mae: 0.1774\n",
            "Epoch 40/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0329 - mae: 0.1433 - val_loss: 0.0495 - val_mae: 0.1743\n",
            "Epoch 41/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0317 - mae: 0.1416 - val_loss: 0.0497 - val_mae: 0.1765\n",
            "Epoch 42/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0310 - mae: 0.1415 - val_loss: 0.0498 - val_mae: 0.1752\n",
            "Epoch 43/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0321 - mae: 0.1425 - val_loss: 0.0493 - val_mae: 0.1745\n",
            "Epoch 44/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0317 - mae: 0.1409 - val_loss: 0.0503 - val_mae: 0.1757\n",
            "Epoch 45/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0344 - mae: 0.1464 - val_loss: 0.0493 - val_mae: 0.1744\n",
            "Epoch 46/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0303 - mae: 0.1377 - val_loss: 0.0504 - val_mae: 0.1771\n",
            "Epoch 47/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0308 - mae: 0.1411 - val_loss: 0.0498 - val_mae: 0.1732\n",
            "Epoch 48/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0302 - mae: 0.1387 - val_loss: 0.0505 - val_mae: 0.1771\n",
            "Epoch 49/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0316 - mae: 0.1400 - val_loss: 0.0517 - val_mae: 0.1775\n",
            "Epoch 50/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0300 - mae: 0.1376 - val_loss: 0.0500 - val_mae: 0.1770\n",
            "Making predictions...\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step\n",
            "\n",
            "Predicted numbers for next 'A' game: [ 3.  7. 10. 14. 17. 21. 24. 27. 31. 33. 36. 40. 43. 47. 50. 54. 57. 60.\n",
            " 64. 67.]\n",
            "Predicted numbers for next 'P' game: [ 3.  7. 10. 13. 17. 21. 25. 28. 31. 35. 38. 41. 44. 47. 50. 54. 57. 60.\n",
            " 63. 67.]\n",
            "\n",
            "Model A Evaluation:\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0331 - mae: 0.1449 \n",
            "MSE: 0.0334, MAE: 0.1454\n",
            "\n",
            "Model P Evaluation:\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0351 - mae: 0.1487 \n",
            "MSE: 0.0353, MAE: 0.1487\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "\n",
        "def analyze_predictions(model, X, scaler, game_type, actual_data):\n",
        "    # Get predictions\n",
        "    predictions = model.predict(X)\n",
        "    predictions = process_predictions(predictions, scaler)\n",
        "\n",
        "    # Convert predictions to integers\n",
        "    predictions = np.array(predictions).astype(int)\n",
        "\n",
        "    # 1. Show next game prediction\n",
        "    print(f\"\\nPredicted numbers for next {game_type} game:\")\n",
        "    print(sorted(predictions[-1]))\n",
        "\n",
        "    # 1.1 Get top 10 and top 5 predicted numbers\n",
        "    all_numbers = predictions.flatten()\n",
        "    number_freq = Counter(all_numbers)\n",
        "\n",
        "    top_10_numbers = [number for number, freq in number_freq.most_common(10)]\n",
        "    top_5_numbers = top_10_numbers[:5]  # Top 5 are the first 5 of top 10\n",
        "\n",
        "    print(f\"\\nTop 10 most frequently predicted numbers ({game_type} Game):\", top_10_numbers)\n",
        "    print(f\"\\nTop 5 most frequently predicted numbers ({game_type} Game):\", top_5_numbers)\n",
        "\n",
        "    # 2. Visualization of prediction accuracy\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    # 2.1 Prediction vs Actual heatmap\n",
        "    plt.subplot(1, 3, 1)\n",
        "    actual = scaler.inverse_transform(actual_data[-1:])\n",
        "    actual = np.round(actual).astype(int)[0]\n",
        "\n",
        "    comparison_data = pd.DataFrame({\n",
        "        'Predicted': sorted(predictions[-1]),\n",
        "        'Actual': sorted(actual)\n",
        "    })\n",
        "\n",
        "    sns.heatmap(comparison_data.corr(), annot=True, cmap='coolwarm')\n",
        "    plt.title(f'Prediction vs Actual Correlation ({game_type} Game)')\n",
        "\n",
        "    # 2.2 Number frequency distribution\n",
        "    plt.subplot(1, 3, 2)\n",
        "    all_numbers = predictions.flatten()\n",
        "    number_freq = Counter(all_numbers)\n",
        "\n",
        "    plt.bar(number_freq.keys(), number_freq.values())\n",
        "    plt.title(f'Number Frequency in Predictions ({game_type} Game)')\n",
        "    plt.xlabel('Number')\n",
        "    plt.ylabel('Frequency')\n",
        "\n",
        "    # 2.3 Error distribution\n",
        "    plt.subplot(1, 3, 3)\n",
        "    errors = np.abs(predictions - actual).flatten()\n",
        "    plt.hist(errors, bins=20)\n",
        "    plt.title(f'Prediction Error Distribution ({game_type} Game)')\n",
        "    plt.xlabel('Absolute Error')\n",
        "    plt.ylabel('Frequency')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 3. Most frequently predicted numbers\n",
        "    top_numbers = pd.DataFrame.from_dict(number_freq, orient='index', columns=['frequency'])\n",
        "    top_numbers = top_numbers.sort_values('frequency', ascending=False).head(10)\n",
        "    print(f\"\\nTop 10 most frequently predicted numbers ({game_type} Game):\")\n",
        "    print(top_numbers)\n",
        "\n",
        "\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# Call this function for both models\n",
        "#analyze_predictions(model_A, X_A, scaler_A, 'A', y_A)\n",
        "#analyze_predictions(model_P, X_P, scaler_P, 'P', y_P)"
      ],
      "metadata": {
        "id": "8zNtkaOvcJZA"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Input\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional, Conv1D, MaxPooling1D\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def create_features(df):\n",
        "    \"\"\"Create additional features for the model\"\"\"\n",
        "    features = pd.DataFrame()\n",
        "\n",
        "    # Basic statistics of previous numbers\n",
        "    features['mean'] = df.mean(axis=1)\n",
        "    features['std'] = df.std(axis=1)\n",
        "    features['median'] = df.median(axis=1)\n",
        "\n",
        "    # Number range features\n",
        "    features['max_diff'] = df.max(axis=1) - df.min(axis=1)\n",
        "    features['range_1_20'] = df.apply(lambda x: sum(1 for n in x if n <= 20), axis=1)\n",
        "    features['range_21_40'] = df.apply(lambda x: sum(1 for n in x if 20 < n <= 40), axis=1)\n",
        "    features['range_41_60'] = df.apply(lambda x: sum(1 for n in x if 40 < n <= 60), axis=1)\n",
        "    features['range_61_plus'] = df.apply(lambda x: sum(1 for n in x if n > 60), axis=1)\n",
        "\n",
        "    # Consecutive numbers\n",
        "    features['consecutive_count'] = df.apply(lambda x: sum(1 for i in range(len(x)-1) if x.iloc[i+1] - x.iloc[i] == 1), axis=1)\n",
        "\n",
        "    # Even/Odd ratio\n",
        "    features['even_count'] = df.apply(lambda x: sum(1 for n in x if n % 2 == 0), axis=1)\n",
        "    features['odd_count'] = df.apply(lambda x: sum(1 for n in x if n % 2 != 0), axis=1)\n",
        "\n",
        "    return features\n",
        "\n",
        "################\n",
        "\n",
        "################\n",
        "\n",
        "def prepare_improved_data(csv_file):\n",
        "    df = pd.read_csv(csv_file)\n",
        "\n",
        "    # Separate A and P games\n",
        "    df_A = df[df['AP'] == 'A'].drop(['PlayDate', 'AP'], axis=1)\n",
        "    df_P = df[df['AP'] == 'P'].drop(['PlayDate', 'AP'], axis=1)\n",
        "\n",
        "    def process_game_data(game_df):\n",
        "        # Convert to float\n",
        "        game_df = game_df.astype(float)\n",
        "\n",
        "        # Normalize numbers to [0,1] range\n",
        "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "        transformed_data = scaler.fit_transform(game_df.values)\n",
        "        transformed_df = pd.DataFrame(data=transformed_data, columns=game_df.columns)\n",
        "\n",
        "        # Create sequences\n",
        "        number_of_rows = len(transformed_df)\n",
        "        window_length = 5\n",
        "        number_of_features = transformed_df.shape[1]\n",
        "\n",
        "        X = np.empty([number_of_rows - window_length, window_length, number_of_features], dtype=float)\n",
        "        y = np.empty([number_of_rows - window_length, number_of_features], dtype=float)\n",
        "\n",
        "        for i in range(0, number_of_rows - window_length):\n",
        "            X[i] = transformed_df.iloc[i:i+window_length, :]\n",
        "            y[i] = transformed_df.iloc[i+window_length:i+window_length+1, :].values\n",
        "\n",
        "        return X, y, scaler\n",
        "\n",
        "    return process_game_data(df_A), process_game_data(df_P)\n",
        "\n",
        "def create_improved_model(window_length, number_of_features, output_features):\n",
        "    model = Sequential([\n",
        "        Input(shape=(window_length, number_of_features)),\n",
        "\n",
        "        # CNN layers for feature extraction\n",
        "        Conv1D(filters=64, kernel_size=3, padding='same', activation='relu'),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "\n",
        "        # LSTM layers\n",
        "        Bidirectional(LSTM(128, return_sequences=True)),\n",
        "        Dropout(0.4),\n",
        "\n",
        "        Bidirectional(LSTM(64, return_sequences=True)),\n",
        "        Dropout(0.4),\n",
        "\n",
        "        Bidirectional(LSTM(32)),\n",
        "        Dropout(0.4),\n",
        "\n",
        "        # Dense layers\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(0.4),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.4),\n",
        "\n",
        "        # Output layer\n",
        "        Dense(output_features, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss='mse',\n",
        "        metrics=['mae']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def train_improved_model(X, y, game_type):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    model = create_improved_model(X.shape[1], X.shape[2], y.shape[1])\n",
        "\n",
        "    callbacks = [\n",
        "        EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True),\n",
        "        ModelCheckpoint(f'improved_model_{game_type}.keras', save_best_only=True),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=0.0001)\n",
        "    ]\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=300,\n",
        "        batch_size=32,\n",
        "        validation_split=0.2,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    return model, history\n",
        "\n",
        "# Main execution for improved model\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Processing data with improved features...\")\n",
        "    (X_A, y_A, scaler_A), (X_P, y_P, scaler_P) = prepare_improved_data(\"2024.csv\")\n",
        "\n",
        "    print(\"Training improved model A...\")\n",
        "    model_A, history_A = train_improved_model(X_A, y_A, 'A')\n",
        "\n",
        "    print(\"Training improved model P...\")\n",
        "    model_P, history_P = train_improved_model(X_P, y_P, 'P')\n",
        "\n",
        "    # Make predictions and analyze results\n",
        "    #print(\"Analyzing results...\")\n",
        "\n",
        "    #analyze_predictions(model_A, X_A, scaler_A, 'A', y_A)\n",
        "    #analyze_predictions(model_P, X_P, scaler_P, 'P', y_P)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yVmuOrfLcac5",
        "outputId": "1705c329-5926-43ae-ea91-b5922099842b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing data with improved features...\n",
            "Training improved model A...\n",
            "Epoch 1/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 190ms/step - loss: 0.0670 - mae: 0.2183 - val_loss: 0.0701 - val_mae: 0.2258 - learning_rate: 0.0010\n",
            "Epoch 2/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0610 - mae: 0.2074 - val_loss: 0.0542 - val_mae: 0.1947 - learning_rate: 0.0010\n",
            "Epoch 3/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0430 - mae: 0.1716 - val_loss: 0.0465 - val_mae: 0.1617 - learning_rate: 0.0010\n",
            "Epoch 4/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0394 - mae: 0.1578 - val_loss: 0.0440 - val_mae: 0.1650 - learning_rate: 0.0010\n",
            "Epoch 5/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0367 - mae: 0.1554 - val_loss: 0.0447 - val_mae: 0.1693 - learning_rate: 0.0010\n",
            "Epoch 6/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0358 - mae: 0.1539 - val_loss: 0.0437 - val_mae: 0.1608 - learning_rate: 0.0010\n",
            "Epoch 7/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0353 - mae: 0.1478 - val_loss: 0.0436 - val_mae: 0.1619 - learning_rate: 0.0010\n",
            "Epoch 8/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0349 - mae: 0.1501 - val_loss: 0.0438 - val_mae: 0.1644 - learning_rate: 0.0010\n",
            "Epoch 9/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0355 - mae: 0.1520 - val_loss: 0.0435 - val_mae: 0.1613 - learning_rate: 0.0010\n",
            "Epoch 10/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0345 - mae: 0.1489 - val_loss: 0.0434 - val_mae: 0.1610 - learning_rate: 0.0010\n",
            "Epoch 11/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0345 - mae: 0.1476 - val_loss: 0.0434 - val_mae: 0.1610 - learning_rate: 0.0010\n",
            "Epoch 12/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0341 - mae: 0.1479 - val_loss: 0.0435 - val_mae: 0.1618 - learning_rate: 0.0010\n",
            "Epoch 13/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0317 - mae: 0.1418 - val_loss: 0.0435 - val_mae: 0.1614 - learning_rate: 0.0010\n",
            "Epoch 14/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0322 - mae: 0.1438 - val_loss: 0.0436 - val_mae: 0.1597 - learning_rate: 0.0010\n",
            "Epoch 15/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0327 - mae: 0.1436 - val_loss: 0.0435 - val_mae: 0.1618 - learning_rate: 0.0010\n",
            "Epoch 16/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0355 - mae: 0.1500 - val_loss: 0.0435 - val_mae: 0.1610 - learning_rate: 0.0010\n",
            "Epoch 17/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0329 - mae: 0.1438 - val_loss: 0.0435 - val_mae: 0.1602 - learning_rate: 0.0010\n",
            "Epoch 18/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0331 - mae: 0.1460 - val_loss: 0.0435 - val_mae: 0.1607 - learning_rate: 0.0010\n",
            "Epoch 19/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0307 - mae: 0.1406 - val_loss: 0.0435 - val_mae: 0.1607 - learning_rate: 0.0010\n",
            "Epoch 20/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0324 - mae: 0.1449 - val_loss: 0.0436 - val_mae: 0.1597 - learning_rate: 0.0010\n",
            "Epoch 21/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0329 - mae: 0.1457 - val_loss: 0.0435 - val_mae: 0.1613 - learning_rate: 5.0000e-04\n",
            "Epoch 22/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0317 - mae: 0.1422 - val_loss: 0.0435 - val_mae: 0.1609 - learning_rate: 5.0000e-04\n",
            "Epoch 23/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0330 - mae: 0.1455 - val_loss: 0.0436 - val_mae: 0.1599 - learning_rate: 5.0000e-04\n",
            "Epoch 24/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0328 - mae: 0.1442 - val_loss: 0.0436 - val_mae: 0.1600 - learning_rate: 5.0000e-04\n",
            "Epoch 25/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0350 - mae: 0.1491 - val_loss: 0.0436 - val_mae: 0.1607 - learning_rate: 5.0000e-04\n",
            "Epoch 26/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0338 - mae: 0.1460 - val_loss: 0.0436 - val_mae: 0.1614 - learning_rate: 5.0000e-04\n",
            "Epoch 27/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0319 - mae: 0.1429 - val_loss: 0.0437 - val_mae: 0.1597 - learning_rate: 5.0000e-04\n",
            "Epoch 28/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0359 - mae: 0.1506 - val_loss: 0.0437 - val_mae: 0.1594 - learning_rate: 5.0000e-04\n",
            "Epoch 29/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0317 - mae: 0.1414 - val_loss: 0.0436 - val_mae: 0.1606 - learning_rate: 5.0000e-04\n",
            "Epoch 30/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0323 - mae: 0.1442 - val_loss: 0.0436 - val_mae: 0.1611 - learning_rate: 5.0000e-04\n",
            "Epoch 31/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0331 - mae: 0.1471 - val_loss: 0.0437 - val_mae: 0.1604 - learning_rate: 2.5000e-04\n",
            "Epoch 32/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0325 - mae: 0.1452 - val_loss: 0.0437 - val_mae: 0.1600 - learning_rate: 2.5000e-04\n",
            "Epoch 33/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0321 - mae: 0.1405 - val_loss: 0.0438 - val_mae: 0.1599 - learning_rate: 2.5000e-04\n",
            "Epoch 34/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0312 - mae: 0.1399 - val_loss: 0.0437 - val_mae: 0.1601 - learning_rate: 2.5000e-04\n",
            "Epoch 35/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0307 - mae: 0.1385 - val_loss: 0.0437 - val_mae: 0.1607 - learning_rate: 2.5000e-04\n",
            "Epoch 36/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0330 - mae: 0.1449 - val_loss: 0.0437 - val_mae: 0.1606 - learning_rate: 2.5000e-04\n",
            "Epoch 37/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0316 - mae: 0.1421 - val_loss: 0.0438 - val_mae: 0.1600 - learning_rate: 2.5000e-04\n",
            "Epoch 38/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0353 - mae: 0.1484 - val_loss: 0.0437 - val_mae: 0.1612 - learning_rate: 2.5000e-04\n",
            "Epoch 39/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0313 - mae: 0.1398 - val_loss: 0.0438 - val_mae: 0.1604 - learning_rate: 2.5000e-04\n",
            "Epoch 40/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0326 - mae: 0.1441 - val_loss: 0.0439 - val_mae: 0.1599 - learning_rate: 2.5000e-04\n",
            "Training improved model P...\n",
            "Epoch 1/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 224ms/step - loss: 0.0637 - mae: 0.2116 - val_loss: 0.0715 - val_mae: 0.2284 - learning_rate: 0.0010\n",
            "Epoch 2/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0551 - mae: 0.1948 - val_loss: 0.0571 - val_mae: 0.2004 - learning_rate: 0.0010\n",
            "Epoch 3/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0451 - mae: 0.1740 - val_loss: 0.0496 - val_mae: 0.1727 - learning_rate: 0.0010\n",
            "Epoch 4/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0402 - mae: 0.1592 - val_loss: 0.0482 - val_mae: 0.1773 - learning_rate: 0.0010\n",
            "Epoch 5/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0388 - mae: 0.1602 - val_loss: 0.0484 - val_mae: 0.1784 - learning_rate: 0.0010\n",
            "Epoch 6/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0391 - mae: 0.1602 - val_loss: 0.0478 - val_mae: 0.1745 - learning_rate: 0.0010\n",
            "Epoch 7/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0374 - mae: 0.1542 - val_loss: 0.0483 - val_mae: 0.1754 - learning_rate: 0.0010\n",
            "Epoch 8/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0347 - mae: 0.1497 - val_loss: 0.0481 - val_mae: 0.1739 - learning_rate: 0.0010\n",
            "Epoch 9/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0351 - mae: 0.1494 - val_loss: 0.0481 - val_mae: 0.1749 - learning_rate: 0.0010\n",
            "Epoch 10/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0358 - mae: 0.1511 - val_loss: 0.0476 - val_mae: 0.1736 - learning_rate: 0.0010\n",
            "Epoch 11/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0368 - mae: 0.1533 - val_loss: 0.0479 - val_mae: 0.1753 - learning_rate: 0.0010\n",
            "Epoch 12/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0352 - mae: 0.1524 - val_loss: 0.0477 - val_mae: 0.1725 - learning_rate: 0.0010\n",
            "Epoch 13/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0348 - mae: 0.1481 - val_loss: 0.0480 - val_mae: 0.1739 - learning_rate: 0.0010\n",
            "Epoch 14/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0353 - mae: 0.1504 - val_loss: 0.0480 - val_mae: 0.1740 - learning_rate: 0.0010\n",
            "Epoch 15/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0350 - mae: 0.1499 - val_loss: 0.0479 - val_mae: 0.1733 - learning_rate: 0.0010\n",
            "Epoch 16/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0357 - mae: 0.1503 - val_loss: 0.0480 - val_mae: 0.1733 - learning_rate: 0.0010\n",
            "Epoch 17/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0348 - mae: 0.1487 - val_loss: 0.0481 - val_mae: 0.1752 - learning_rate: 0.0010\n",
            "Epoch 18/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0352 - mae: 0.1498 - val_loss: 0.0479 - val_mae: 0.1721 - learning_rate: 0.0010\n",
            "Epoch 19/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0350 - mae: 0.1500 - val_loss: 0.0479 - val_mae: 0.1721 - learning_rate: 0.0010\n",
            "Epoch 20/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0352 - mae: 0.1502 - val_loss: 0.0481 - val_mae: 0.1750 - learning_rate: 0.0010\n",
            "Epoch 21/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0358 - mae: 0.1522 - val_loss: 0.0480 - val_mae: 0.1739 - learning_rate: 5.0000e-04\n",
            "Epoch 22/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0369 - mae: 0.1529 - val_loss: 0.0478 - val_mae: 0.1711 - learning_rate: 5.0000e-04\n",
            "Epoch 23/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0334 - mae: 0.1456 - val_loss: 0.0477 - val_mae: 0.1722 - learning_rate: 5.0000e-04\n",
            "Epoch 24/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0337 - mae: 0.1468 - val_loss: 0.0478 - val_mae: 0.1729 - learning_rate: 5.0000e-04\n",
            "Epoch 25/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0343 - mae: 0.1473 - val_loss: 0.0477 - val_mae: 0.1721 - learning_rate: 5.0000e-04\n",
            "Epoch 26/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0379 - mae: 0.1545 - val_loss: 0.0477 - val_mae: 0.1719 - learning_rate: 5.0000e-04\n",
            "Epoch 27/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0352 - mae: 0.1492 - val_loss: 0.0477 - val_mae: 0.1725 - learning_rate: 5.0000e-04\n",
            "Epoch 28/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0333 - mae: 0.1451 - val_loss: 0.0478 - val_mae: 0.1731 - learning_rate: 5.0000e-04\n",
            "Epoch 29/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0324 - mae: 0.1424 - val_loss: 0.0477 - val_mae: 0.1718 - learning_rate: 5.0000e-04\n",
            "Epoch 30/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0333 - mae: 0.1443 - val_loss: 0.0478 - val_mae: 0.1719 - learning_rate: 5.0000e-04\n",
            "Epoch 31/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0344 - mae: 0.1483 - val_loss: 0.0478 - val_mae: 0.1723 - learning_rate: 2.5000e-04\n",
            "Epoch 32/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0333 - mae: 0.1447 - val_loss: 0.0478 - val_mae: 0.1723 - learning_rate: 2.5000e-04\n",
            "Epoch 33/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0335 - mae: 0.1472 - val_loss: 0.0478 - val_mae: 0.1720 - learning_rate: 2.5000e-04\n",
            "Epoch 34/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0336 - mae: 0.1461 - val_loss: 0.0478 - val_mae: 0.1723 - learning_rate: 2.5000e-04\n",
            "Epoch 35/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0333 - mae: 0.1461 - val_loss: 0.0478 - val_mae: 0.1719 - learning_rate: 2.5000e-04\n",
            "Epoch 36/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0331 - mae: 0.1452 - val_loss: 0.0478 - val_mae: 0.1720 - learning_rate: 2.5000e-04\n",
            "Epoch 37/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0341 - mae: 0.1464 - val_loss: 0.0478 - val_mae: 0.1718 - learning_rate: 2.5000e-04\n",
            "Epoch 38/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0343 - mae: 0.1483 - val_loss: 0.0477 - val_mae: 0.1714 - learning_rate: 2.5000e-04\n",
            "Epoch 39/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0342 - mae: 0.1479 - val_loss: 0.0477 - val_mae: 0.1715 - learning_rate: 2.5000e-04\n",
            "Epoch 40/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0350 - mae: 0.1497 - val_loss: 0.0477 - val_mae: 0.1711 - learning_rate: 2.5000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "\n",
        "# Make predictions and analyze results\n",
        "print(\"Analyzing results...\")\n",
        "\n",
        "def make_predictions(model, X, scaler, game_type, actual_data):\n",
        "    # Get predictions\n",
        "    predictions = model.predict(X)\n",
        "    predictions = process_predictions(predictions, scaler)\n",
        "\n",
        "    # Convert predictions to integers\n",
        "    predictions = np.array(predictions).astype(int)\n",
        "\n",
        "    # 1. Show next game prediction\n",
        "    print(f\"\\nPredicted numbers for next {game_type} game:\")\n",
        "    print(sorted(predictions[-1]))\n",
        "\n",
        "    # For each prediction, we will select the top 10 numbers with the highest confidence\n",
        "    # `predictions[-1]` is the prediction for the next game\n",
        "    prediction_scores = predictions[-1]\n",
        "\n",
        "    # Get the indices of the top 10 predictions with the highest confidence\n",
        "    top_10_indices = np.argsort(prediction_scores)[::-1][:10]\n",
        "\n",
        "    # Retrieve the top 10 predicted numbers using these indices\n",
        "    top_10_predictions = prediction_scores[top_10_indices]\n",
        "\n",
        "    # Convert the top 10 predictions to integers\n",
        "    top_10_predictions = np.array(top_10_predictions).astype(int)\n",
        "\n",
        "    # 1. Show the top 10 predictions based on confidence\n",
        "    print(f\"\\nTop 10 predicted numbers with the most confidence for next {game_type} game:\")\n",
        "    print(sorted(top_10_predictions))\n",
        "\n",
        "\n",
        "print(\"######################\")\n",
        "make_predictions(model_A, X_A, scaler_A, 'A', y_A)\n",
        "make_predictions(model_P, X_P, scaler_P, 'P', y_P)\n",
        "\n",
        "#analyze_predictions(model_A, X_A, scaler_A, 'A', y_A)\n",
        "#analyze_predictions(model_P, X_P, scaler_P, 'P', y_P)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "O-PAnhEcd27L",
        "outputId": "7cc49ea1-d631-4ad0-ea91-c32fde1756b5"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing results...\n",
            "######################\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step\n",
            "\n",
            "Predicted numbers for next A game:\n",
            "[3, 7, 10, 14, 17, 20, 24, 27, 31, 33, 36, 40, 44, 47, 50, 54, 57, 61, 64, 67]\n",
            "\n",
            "Top 10 predicted numbers with the most confidence for next A game:\n",
            "[36, 40, 44, 47, 50, 54, 57, 61, 64, 67]\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step\n",
            "\n",
            "Predicted numbers for next P game:\n",
            "[4, 8, 10, 14, 17, 21, 25, 29, 32, 35, 38, 41, 44, 47, 51, 54, 57, 60, 63, 67]\n",
            "\n",
            "Top 10 predicted numbers with the most confidence for next P game:\n",
            "[38, 41, 44, 47, 51, 54, 57, 60, 63, 67]\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}