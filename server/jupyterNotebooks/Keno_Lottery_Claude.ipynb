{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Snowdenstyll/Lottery/blob/main/server/jupyterNotebooks/Keno_Lottery_Claude.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Input\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "\n",
        "# Data Preprocessing\n",
        "def prepare_data(csv_file):\n",
        "    # Read the data\n",
        "    df = pd.read_csv(csv_file)\n",
        "\n",
        "    # Separate A and P games\n",
        "    df_A = df[df['AP'] == 'A'].drop(['PlayDate', 'AP'], axis=1)\n",
        "    df_P = df[df['AP'] == 'P'].drop(['PlayDate', 'AP'], axis=1)\n",
        "\n",
        "    # Process each game type separately\n",
        "    def process_game_data(game_df):\n",
        "        # Convert to float\n",
        "        game_df = game_df.astype(float)\n",
        "\n",
        "        # Normalize numbers to [0,1] range\n",
        "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "        transformed_data = scaler.fit_transform(game_df.values)\n",
        "        transformed_df = pd.DataFrame(data=transformed_data, columns=game_df.columns)\n",
        "\n",
        "        # Create sequences\n",
        "        number_of_rows = len(transformed_df)\n",
        "        window_length = 5\n",
        "        number_of_features = transformed_df.shape[1]\n",
        "\n",
        "        X = np.empty([number_of_rows - window_length, window_length, number_of_features], dtype=float)\n",
        "        y = np.empty([number_of_rows - window_length, number_of_features], dtype=float)\n",
        "\n",
        "        for i in range(0, number_of_rows - window_length):\n",
        "            X[i] = transformed_df.iloc[i:i+window_length, :]\n",
        "            y[i] = transformed_df.iloc[i+window_length:i+window_length+1, :].values\n",
        "\n",
        "        return X, y, scaler\n",
        "\n",
        "    return process_game_data(df_A), process_game_data(df_P)\n",
        "\n",
        "# Create the model\n",
        "def create_model(window_length, number_of_features):\n",
        "    model = Sequential([\n",
        "        Input(shape=(window_length, number_of_features)),  # Explicit input layer\n",
        "        Bidirectional(LSTM(128, return_sequences=True)),\n",
        "        Dropout(0.3),\n",
        "        Bidirectional(LSTM(64)),\n",
        "        Dropout(0.3),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(number_of_features, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                 loss='mse',\n",
        "                 metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "# Train separate models for A and P games\n",
        "def train_model(X, y, game_type):\n",
        "    try:\n",
        "        # Split the data\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Create and train the model\n",
        "        model = create_model(X.shape[1], X.shape[2])\n",
        "\n",
        "        callbacks = [\n",
        "            EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True),\n",
        "            ModelCheckpoint(f'best_model_{game_type}.keras',  # Changed extension to .keras\n",
        "                          save_best_only=True,\n",
        "                          monitor='val_loss')\n",
        "        ]\n",
        "\n",
        "        history = model.fit(X_train, y_train,\n",
        "                          epochs=200,\n",
        "                          batch_size=32,\n",
        "                          validation_split=0.2,\n",
        "                          callbacks=callbacks,\n",
        "                          verbose=1)\n",
        "\n",
        "        return model, history\n",
        "    except Exception as e:\n",
        "        print(f\"Error training model for game type {game_type}: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "# Function to convert predictions back to actual numbers\n",
        "''' def process_predictions(predictions, scaler, original_features_count=20):\n",
        "    try:\n",
        "        # Inverse transform the normalized predictions\n",
        "        predictions_original = scaler.inverse_transform(predictions)\n",
        "\n",
        "        # Round to nearest integers and ensure unique numbers\n",
        "        rounded_predictions = []\n",
        "        for pred in predictions_original:\n",
        "            # Sort numbers and round them\n",
        "            sorted_numbers = np.sort(np.round(pred))\n",
        "            # Ensure no duplicates and numbers are within range\n",
        "            unique_numbers = np.unique(np.clip(sorted_numbers, 1, 69))\n",
        "            # If we don't have exactly 20 numbers, adjust\n",
        "            while len(unique_numbers) < original_features_count:\n",
        "                # Add missing numbers\n",
        "                available_numbers = set(range(1, 70)) - set(unique_numbers)\n",
        "                unique_numbers = np.append(unique_numbers, np.random.choice(list(available_numbers)))\n",
        "                unique_numbers = np.sort(unique_numbers)\n",
        "            rounded_predictions.append(unique_numbers[:20])\n",
        "\n",
        "        return rounded_predictions\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing predictions: {str(e)}\")\n",
        "        raise '''\n",
        "\n",
        "def process_predictions(predictions, scaler, original_features_count=20, top_n=10):\n",
        "    try:\n",
        "        # Inverse transform the predictions\n",
        "        predictions_original = scaler.inverse_transform(predictions)\n",
        "        processed_predictions = []\n",
        "\n",
        "        for pred in predictions_original:\n",
        "            # Create pairs of (number, confidence)\n",
        "            number_confidence_pairs = list(enumerate(pred))\n",
        "\n",
        "            # Sort by confidence (second element of pair) in descending order\n",
        "            sorted_pairs = sorted(number_confidence_pairs, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "            # DEBUG: Print sorted pairs with their confidence scores\n",
        "            print(f\"\\nSorted pairs (number, confidence): {sorted_pairs[:15]}\")  # Just print top 15 for debugging\n",
        "\n",
        "            # Get the top 10 indices (by highest confidence)\n",
        "            top_indices = [pair[0] for pair in sorted_pairs[:top_n]]\n",
        "\n",
        "            # DEBUG: Print the top indices\n",
        "            print(f\"Top {top_n} indices: {top_indices}\")\n",
        "\n",
        "            # Get the corresponding top numbers\n",
        "            top_numbers = np.sort(np.round(pred[top_indices])).astype(int)\n",
        "\n",
        "            # Ensure unique numbers and restrict to range [1, 69]\n",
        "            unique_numbers = np.unique(np.clip(top_numbers, 1, 69))\n",
        "\n",
        "            # If there are less than 10 unique numbers, fill in missing ones\n",
        "            while len(unique_numbers) < top_n:\n",
        "                available_numbers = set(range(1, 70)) - set(unique_numbers)\n",
        "                unique_numbers = np.append(unique_numbers, np.random.choice(list(available_numbers)))\n",
        "                unique_numbers = np.sort(unique_numbers)\n",
        "\n",
        "            # DEBUG: Print the final top numbers after uniqueness and range enforcement\n",
        "            print(f\"Final top {top_n} numbers: {unique_numbers[:top_n]}\")\n",
        "\n",
        "            processed_predictions.append({\n",
        "                'numbers': unique_numbers[:top_n].astype(int),\n",
        "                'confidence': np.mean([pair[1] for pair in sorted_pairs[:top_n]])  # Average confidence of top 10\n",
        "            })\n",
        "\n",
        "        # Sort all predictions by confidence score\n",
        "        sorted_predictions = sorted(processed_predictions,\n",
        "                                    key=lambda x: x['confidence'],\n",
        "                                    reverse=True)\n",
        "\n",
        "        # Format the output to return top N predictions\n",
        "        formatted_output = []\n",
        "        for i, pred in enumerate(sorted_predictions[:top_n], 1):\n",
        "            formatted_output.append({\n",
        "                'rank': i,\n",
        "                'numbers': pred['numbers'].tolist(),\n",
        "                'confidence_score': round(float(pred['confidence']), 2)\n",
        "            })\n",
        "\n",
        "        return formatted_output\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing predictions: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def display_predictions(predictions, game_type):\n",
        "    try:\n",
        "        if predictions:\n",
        "            for pred in predictions:\n",
        "                numbers_str = ', '.join(map(str, pred['numbers']))\n",
        "                print(f\"\\nGame Type: {game_type}\")\n",
        "                print(f\"Rank: {pred['rank']}\")\n",
        "                print(f\"Numbers: {numbers_str}\")\n",
        "                print(f\"Confidence Score: {pred['confidence_score']:.2f}\")\n",
        "                print(\"-\" * 50)\n",
        "    except Exception as e:\n",
        "        print(f\"Error in display_predictions: {str(e)}\")\n",
        "\n",
        "def analyze_predictions(model, X, scaler, game_type, actual_data):\n",
        "    # Get predictions\n",
        "    predictions = model.predict(X)\n",
        "    predictions = process_predictions(predictions, scaler)\n",
        "\n",
        "    # Convert predictions to integers\n",
        "    predictions = np.array(predictions).astype(int)\n",
        "\n",
        "    # 1. Show next game prediction\n",
        "    print(f\"\\nPredicted numbers for next {game_type} game:\")\n",
        "    print(sorted(predictions[-1]))\n",
        "\n",
        "    # 1.1 Get top 10 and top 5 predicted numbers\n",
        "    all_numbers = predictions.flatten()\n",
        "    number_freq = Counter(all_numbers)\n",
        "\n",
        "    top_10_numbers = [number for number, freq in number_freq.most_common(10)]\n",
        "    top_5_numbers = top_10_numbers[:5]  # Top 5 are the first 5 of top 10\n",
        "\n",
        "    print(f\"\\nTop 10 most frequently predicted numbers ({game_type} Game):\", top_10_numbers)\n",
        "    print(f\"\\nTop 5 most frequently predicted numbers ({game_type} Game):\", top_5_numbers)\n",
        "\n",
        "    # 2. Visualization of prediction accuracy\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    # 2.1 Prediction vs Actual heatmap\n",
        "    plt.subplot(1, 3, 1)\n",
        "    actual = scaler.inverse_transform(actual_data[-1:])\n",
        "    actual = np.round(actual).astype(int)[0]\n",
        "\n",
        "    comparison_data = pd.DataFrame({\n",
        "        'Predicted': sorted(predictions[-1]),\n",
        "        'Actual': sorted(actual)\n",
        "    })\n",
        "\n",
        "    sns.heatmap(comparison_data.corr(), annot=True, cmap='coolwarm')\n",
        "    plt.title(f'Prediction vs Actual Correlation ({game_type} Game)')\n",
        "\n",
        "    # 2.2 Number frequency distribution\n",
        "    plt.subplot(1, 3, 2)\n",
        "    all_numbers = predictions.flatten()\n",
        "    number_freq = Counter(all_numbers)\n",
        "\n",
        "    plt.bar(number_freq.keys(), number_freq.values())\n",
        "    plt.title(f'Number Frequency in Predictions ({game_type} Game)')\n",
        "    plt.xlabel('Number')\n",
        "    plt.ylabel('Frequency')\n",
        "\n",
        "    # 2.3 Error distribution\n",
        "    plt.subplot(1, 3, 3)\n",
        "    errors = np.abs(predictions - actual).flatten()\n",
        "    plt.hist(errors, bins=20)\n",
        "    plt.title(f'Prediction Error Distribution ({game_type} Game)')\n",
        "    plt.xlabel('Absolute Error')\n",
        "    plt.ylabel('Frequency')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 3. Most frequently predicted numbers\n",
        "    top_numbers = pd.DataFrame.from_dict(number_freq, orient='index', columns=['frequency'])\n",
        "    top_numbers = top_numbers.sort_values('frequency', ascending=False).head(10)\n",
        "    print(f\"\\nTop 10 most frequently predicted numbers ({game_type} Game):\")\n",
        "    print(top_numbers)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "  # Call this function for both models\n",
        "  #analyze_predictions(model_A, X_A, scaler_A, 'A', y_A)\n",
        "  #analyze_predictions(model_P, X_P, scaler_P, 'P', y_P)\n"
      ],
      "metadata": {
        "id": "BphE_sXjahe9",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # Process both game types\n",
        "        print(\"Processing data...\")\n",
        "        (X_A, y_A, scaler_A), (X_P, y_P, scaler_P) = prepare_data(\"2024.csv\")\n",
        "\n",
        "        print(\"Training model A...\")\n",
        "        # Train models for both game types\n",
        "        model_A, history_A = train_model(X_A, y_A, 'A')\n",
        "\n",
        "        print(\"Training model P...\")\n",
        "        model_P, history_P = train_model(X_P, y_P, 'P')\n",
        "\n",
        "        # Make predictions for next games\n",
        "        print(\"Making predictions...\")\n",
        "        last_sequence_A = X_A[-1:]\n",
        "        last_sequence_P = X_P[-1:]\n",
        "\n",
        "        print(\"Predicting next 'A' game numbers...\")\n",
        "        print(\"Predicting next 'P' game numbers...\")\n",
        "\n",
        "        pred_A = model_A.predict(last_sequence_A)\n",
        "        pred_P = model_P.predict(last_sequence_P)\n",
        "\n",
        "        # Convert predictions to actual numbers\n",
        "        numbers_A = process_predictions(pred_A, scaler_A)\n",
        "        numbers_P = process_predictions(pred_P, scaler_P)\n",
        "\n",
        "        print(\"\\nPredicted numbers for next 'A' game:\", numbers_A[0])\n",
        "        print(\"Predicted numbers for next 'P' game:\", numbers_P[0])\n",
        "\n",
        "        # Evaluate models\n",
        "        print(\"\\nModel A Evaluation:\")\n",
        "        loss_A = model_A.evaluate(X_A, y_A)\n",
        "        print(f\"MSE: {loss_A[0]:.4f}, MAE: {loss_A[1]:.4f}\")\n",
        "\n",
        "        print(\"\\nModel P Evaluation:\")\n",
        "        loss_P = model_P.evaluate(X_P, y_P)\n",
        "        print(f\"MSE: {loss_P[0]:.4f}, MAE: {loss_P[1]:.4f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {str(e)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "v8NkM80ukhWu",
        "outputId": "61c634a6-7521-4455-8421-3324f2ca1298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing data...\n",
            "Training model A...\n",
            "Epoch 1/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 108ms/step - loss: 0.0614 - mae: 0.2083 - val_loss: 0.0507 - val_mae: 0.1856\n",
            "Epoch 2/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0390 - mae: 0.1614 - val_loss: 0.0462 - val_mae: 0.1587\n",
            "Epoch 3/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0344 - mae: 0.1433 - val_loss: 0.0447 - val_mae: 0.1640\n",
            "Epoch 4/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0334 - mae: 0.1467 - val_loss: 0.0437 - val_mae: 0.1646\n",
            "Epoch 5/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0327 - mae: 0.1448 - val_loss: 0.0436 - val_mae: 0.1589\n",
            "Epoch 6/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0328 - mae: 0.1441 - val_loss: 0.0434 - val_mae: 0.1594\n",
            "Epoch 7/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0326 - mae: 0.1444 - val_loss: 0.0436 - val_mae: 0.1610\n",
            "Epoch 8/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0300 - mae: 0.1396 - val_loss: 0.0438 - val_mae: 0.1592\n",
            "Epoch 9/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0336 - mae: 0.1455 - val_loss: 0.0437 - val_mae: 0.1589\n",
            "Epoch 10/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0340 - mae: 0.1455 - val_loss: 0.0434 - val_mae: 0.1622\n",
            "Epoch 11/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0317 - mae: 0.1423 - val_loss: 0.0435 - val_mae: 0.1590\n",
            "Epoch 12/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0317 - mae: 0.1422 - val_loss: 0.0435 - val_mae: 0.1590\n",
            "Epoch 13/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0317 - mae: 0.1408 - val_loss: 0.0434 - val_mae: 0.1607\n",
            "Epoch 14/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0336 - mae: 0.1470 - val_loss: 0.0437 - val_mae: 0.1593\n",
            "Epoch 15/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0318 - mae: 0.1418 - val_loss: 0.0438 - val_mae: 0.1594\n",
            "Epoch 16/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0308 - mae: 0.1380 - val_loss: 0.0435 - val_mae: 0.1605\n",
            "Epoch 17/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0307 - mae: 0.1399 - val_loss: 0.0437 - val_mae: 0.1592\n",
            "Epoch 18/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0305 - mae: 0.1383 - val_loss: 0.0435 - val_mae: 0.1606\n",
            "Epoch 19/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0314 - mae: 0.1412 - val_loss: 0.0437 - val_mae: 0.1590\n",
            "Epoch 20/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0312 - mae: 0.1408 - val_loss: 0.0435 - val_mae: 0.1597\n",
            "Epoch 21/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0324 - mae: 0.1418 - val_loss: 0.0436 - val_mae: 0.1594\n",
            "Epoch 22/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0324 - mae: 0.1428 - val_loss: 0.0438 - val_mae: 0.1588\n",
            "Epoch 23/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0301 - mae: 0.1371 - val_loss: 0.0436 - val_mae: 0.1596\n",
            "Epoch 24/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0322 - mae: 0.1416 - val_loss: 0.0436 - val_mae: 0.1600\n",
            "Epoch 25/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0315 - mae: 0.1425 - val_loss: 0.0438 - val_mae: 0.1589\n",
            "Epoch 26/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0313 - mae: 0.1411 - val_loss: 0.0435 - val_mae: 0.1597\n",
            "Epoch 27/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0334 - mae: 0.1471 - val_loss: 0.0440 - val_mae: 0.1586\n",
            "Epoch 28/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0307 - mae: 0.1372 - val_loss: 0.0436 - val_mae: 0.1590\n",
            "Epoch 29/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0311 - mae: 0.1412 - val_loss: 0.0434 - val_mae: 0.1609\n",
            "Epoch 30/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0328 - mae: 0.1443 - val_loss: 0.0446 - val_mae: 0.1583\n",
            "Epoch 31/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0324 - mae: 0.1420 - val_loss: 0.0434 - val_mae: 0.1609\n",
            "Epoch 32/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0318 - mae: 0.1425 - val_loss: 0.0438 - val_mae: 0.1583\n",
            "Epoch 33/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0309 - mae: 0.1376 - val_loss: 0.0438 - val_mae: 0.1581\n",
            "Training model P...\n",
            "Epoch 1/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 107ms/step - loss: 0.0556 - mae: 0.1955 - val_loss: 0.0530 - val_mae: 0.1877\n",
            "Epoch 2/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0393 - mae: 0.1604 - val_loss: 0.0494 - val_mae: 0.1690\n",
            "Epoch 3/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0368 - mae: 0.1501 - val_loss: 0.0477 - val_mae: 0.1747\n",
            "Epoch 4/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0354 - mae: 0.1508 - val_loss: 0.0479 - val_mae: 0.1747\n",
            "Epoch 5/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0379 - mae: 0.1547 - val_loss: 0.0479 - val_mae: 0.1715\n",
            "Epoch 6/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0357 - mae: 0.1493 - val_loss: 0.0485 - val_mae: 0.1723\n",
            "Epoch 7/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0378 - mae: 0.1540 - val_loss: 0.0481 - val_mae: 0.1725\n",
            "Epoch 8/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0337 - mae: 0.1459 - val_loss: 0.0478 - val_mae: 0.1725\n",
            "Epoch 9/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0343 - mae: 0.1475 - val_loss: 0.0476 - val_mae: 0.1716\n",
            "Epoch 10/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0330 - mae: 0.1457 - val_loss: 0.0481 - val_mae: 0.1738\n",
            "Epoch 11/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0350 - mae: 0.1496 - val_loss: 0.0481 - val_mae: 0.1722\n",
            "Epoch 12/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0342 - mae: 0.1463 - val_loss: 0.0483 - val_mae: 0.1729\n",
            "Epoch 13/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0337 - mae: 0.1453 - val_loss: 0.0481 - val_mae: 0.1709\n",
            "Epoch 14/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0331 - mae: 0.1438 - val_loss: 0.0475 - val_mae: 0.1705\n",
            "Epoch 15/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0323 - mae: 0.1434 - val_loss: 0.0478 - val_mae: 0.1738\n",
            "Epoch 16/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0343 - mae: 0.1474 - val_loss: 0.0479 - val_mae: 0.1716\n",
            "Epoch 17/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0342 - mae: 0.1463 - val_loss: 0.0483 - val_mae: 0.1712\n",
            "Epoch 18/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0338 - mae: 0.1471 - val_loss: 0.0481 - val_mae: 0.1730\n",
            "Epoch 19/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0348 - mae: 0.1488 - val_loss: 0.0475 - val_mae: 0.1706\n",
            "Epoch 20/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0327 - mae: 0.1424 - val_loss: 0.0478 - val_mae: 0.1713\n",
            "Epoch 21/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0332 - mae: 0.1447 - val_loss: 0.0476 - val_mae: 0.1716\n",
            "Epoch 22/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0321 - mae: 0.1429 - val_loss: 0.0473 - val_mae: 0.1700\n",
            "Epoch 23/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0355 - mae: 0.1494 - val_loss: 0.0479 - val_mae: 0.1716\n",
            "Epoch 24/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0322 - mae: 0.1419 - val_loss: 0.0478 - val_mae: 0.1719\n",
            "Epoch 25/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0330 - mae: 0.1443 - val_loss: 0.0483 - val_mae: 0.1705\n",
            "Epoch 26/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0339 - mae: 0.1450 - val_loss: 0.0478 - val_mae: 0.1721\n",
            "Epoch 27/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0338 - mae: 0.1470 - val_loss: 0.0475 - val_mae: 0.1701\n",
            "Epoch 28/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0319 - mae: 0.1420 - val_loss: 0.0477 - val_mae: 0.1731\n",
            "Epoch 29/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0342 - mae: 0.1476 - val_loss: 0.0479 - val_mae: 0.1713\n",
            "Epoch 30/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0338 - mae: 0.1464 - val_loss: 0.0481 - val_mae: 0.1711\n",
            "Epoch 31/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0325 - mae: 0.1435 - val_loss: 0.0482 - val_mae: 0.1719\n",
            "Epoch 32/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0318 - mae: 0.1430 - val_loss: 0.0484 - val_mae: 0.1724\n",
            "Epoch 33/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0328 - mae: 0.1440 - val_loss: 0.0475 - val_mae: 0.1717\n",
            "Epoch 34/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0331 - mae: 0.1439 - val_loss: 0.0476 - val_mae: 0.1713\n",
            "Epoch 35/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0318 - mae: 0.1397 - val_loss: 0.0481 - val_mae: 0.1732\n",
            "Epoch 36/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0313 - mae: 0.1416 - val_loss: 0.0484 - val_mae: 0.1740\n",
            "Epoch 37/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0319 - mae: 0.1416 - val_loss: 0.0473 - val_mae: 0.1722\n",
            "Epoch 38/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0318 - mae: 0.1412 - val_loss: 0.0504 - val_mae: 0.1769\n",
            "Epoch 39/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0330 - mae: 0.1451 - val_loss: 0.0484 - val_mae: 0.1709\n",
            "Epoch 40/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0335 - mae: 0.1444 - val_loss: 0.0480 - val_mae: 0.1771\n",
            "Epoch 41/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0329 - mae: 0.1460 - val_loss: 0.0494 - val_mae: 0.1715\n",
            "Epoch 42/200\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0335 - mae: 0.1437 - val_loss: 0.0489 - val_mae: 0.1736\n",
            "Making predictions...\n",
            "Predicting next 'A' game numbers...\n",
            "Predicting next 'P' game numbers...\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step\n",
            "\n",
            "Predicted numbers for next 'A' game: {'rank': 1, 'numbers': [3.0, 7.0, 10.0, 14.0, 17.0, 21.0, 24.0, 27.0, 31.0, 33.0, 37.0, 40.0, 43.0, 47.0, 51.0, 54.0, 57.0, 60.0, 64.0, 67.0], 'confidence_score': 10.082579612731934}\n",
            "Predicted numbers for next 'P' game: {'rank': 1, 'numbers': [3.0, 7.0, 10.0, 13.0, 17.0, 21.0, 25.0, 28.0, 31.0, 35.0, 38.0, 41.0, 45.0, 48.0, 50.0, 54.0, 57.0, 60.0, 64.0, 67.0], 'confidence_score': 9.422861099243164}\n",
            "\n",
            "Model A Evaluation:\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0330 - mae: 0.1444 \n",
            "MSE: 0.0333, MAE: 0.1448\n",
            "\n",
            "Model P Evaluation:\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0353 - mae: 0.1483 \n",
            "MSE: 0.0355, MAE: 0.1484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_A = model_A.predict(last_sequence_A)\n",
        "top_10_predictions_A = process_predictions(predictions_A, scaler_A, original_features_count=10, top_n=10)\n",
        "\n",
        "predictions_P = model_P.predict(last_sequence_P)\n",
        "top_10_predictions_P = process_predictions(predictions_P, scaler_P, original_features_count=10, top_n=10)\n",
        "\n",
        "display_predictions(top_10_predictions_A, 'A')\n",
        "display_predictions(top_10_predictions_P, 'P')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMm42cdim4PD",
        "outputId": "bd058bf7-f1b9-4d95-f236-cee2cd0fa902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\n",
            "Sorted pairs (number, confidence): [(19, 67.30063), (18, 63.95086), (17, 60.706852), (16, 57.375664), (15, 54.109886), (14, 50.715282), (13, 47.297832), (12, 43.827694), (11, 40.447495), (10, 36.954765), (9, 33.909683), (8, 30.642344), (7, 27.690271), (6, 24.018663), (5, 20.456509)]\n",
            "Top 10 indices: [19, 18, 17, 16, 15, 14, 13, 12, 11, 10]\n",
            "Final top 10 numbers: [37 40 44 47 51 54 57 61 64 67]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\n",
            "Sorted pairs (number, confidence): [(19, 66.860695), (18, 63.593044), (17, 60.47284), (16, 57.694374), (15, 54.209644), (14, 50.24315), (13, 47.719685), (12, 44.555893), (11, 40.414143), (10, 37.85281), (9, 34.899616), (8, 31.538483), (7, 27.630959), (6, 24.703793), (5, 20.661854)]\n",
            "Top 10 indices: [19, 18, 17, 16, 15, 14, 13, 12, 11, 10]\n",
            "Final top 10 numbers: [38 40 45 48 50 54 58 60 64 67]\n",
            "\n",
            "Game Type: A\n",
            "Rank: 1\n",
            "Numbers: 37, 40, 44, 47, 51, 54, 57, 61, 64, 67\n",
            "Confidence Score: 52.27\n",
            "--------------------------------------------------\n",
            "\n",
            "Game Type: P\n",
            "Rank: 1\n",
            "Numbers: 38, 40, 45, 48, 50, 54, 58, 60, 64, 67\n",
            "Confidence Score: 52.36\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Input\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional, Conv1D, MaxPooling1D\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def create_features(df):\n",
        "    \"\"\"Create additional features for the model\"\"\"\n",
        "    features = pd.DataFrame()\n",
        "\n",
        "    # Basic statistics of previous numbers\n",
        "    features['mean'] = df.mean(axis=1)\n",
        "    features['std'] = df.std(axis=1)\n",
        "    features['median'] = df.median(axis=1)\n",
        "\n",
        "    # Number range features\n",
        "    features['max_diff'] = df.max(axis=1) - df.min(axis=1)\n",
        "    features['range_1_20'] = df.apply(lambda x: sum(1 for n in x if n <= 20), axis=1)\n",
        "    features['range_21_40'] = df.apply(lambda x: sum(1 for n in x if 20 < n <= 40), axis=1)\n",
        "    features['range_41_60'] = df.apply(lambda x: sum(1 for n in x if 40 < n <= 60), axis=1)\n",
        "    features['range_61_plus'] = df.apply(lambda x: sum(1 for n in x if n > 60), axis=1)\n",
        "\n",
        "    # Consecutive numbers\n",
        "    features['consecutive_count'] = df.apply(lambda x: sum(1 for i in range(len(x)-1) if x.iloc[i+1] - x.iloc[i] == 1), axis=1)\n",
        "\n",
        "    # Even/Odd ratio\n",
        "    features['even_count'] = df.apply(lambda x: sum(1 for n in x if n % 2 == 0), axis=1)\n",
        "    features['odd_count'] = df.apply(lambda x: sum(1 for n in x if n % 2 != 0), axis=1)\n",
        "\n",
        "    return features\n",
        "\n",
        "################\n",
        "\n",
        "################\n",
        "\n",
        "def prepare_improved_data(csv_file):\n",
        "    df = pd.read_csv(csv_file)\n",
        "\n",
        "    # Separate A and P games\n",
        "    df_A = df[df['AP'] == 'A'].drop(['PlayDate', 'AP'], axis=1)\n",
        "    df_P = df[df['AP'] == 'P'].drop(['PlayDate', 'AP'], axis=1)\n",
        "\n",
        "    def process_game_data(game_df):\n",
        "        # Convert to float\n",
        "        game_df = game_df.astype(float)\n",
        "\n",
        "        # Normalize numbers to [0,1] range\n",
        "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "        transformed_data = scaler.fit_transform(game_df.values)\n",
        "        transformed_df = pd.DataFrame(data=transformed_data, columns=game_df.columns)\n",
        "\n",
        "        # Create sequences\n",
        "        number_of_rows = len(transformed_df)\n",
        "        window_length = 5\n",
        "        number_of_features = transformed_df.shape[1]\n",
        "\n",
        "        X = np.empty([number_of_rows - window_length, window_length, number_of_features], dtype=float)\n",
        "        y = np.empty([number_of_rows - window_length, number_of_features], dtype=float)\n",
        "\n",
        "        for i in range(0, number_of_rows - window_length):\n",
        "            X[i] = transformed_df.iloc[i:i+window_length, :]\n",
        "            y[i] = transformed_df.iloc[i+window_length:i+window_length+1, :].values\n",
        "\n",
        "        return X, y, scaler\n",
        "\n",
        "    return process_game_data(df_A), process_game_data(df_P)\n",
        "\n",
        "def create_improved_model(window_length, number_of_features, output_features):\n",
        "    model = Sequential([\n",
        "        Input(shape=(window_length, number_of_features)),\n",
        "\n",
        "        # CNN layers for feature extraction\n",
        "        Conv1D(filters=64, kernel_size=3, padding='same', activation='relu'),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "\n",
        "        # LSTM layers\n",
        "        Bidirectional(LSTM(128, return_sequences=True)),\n",
        "        Dropout(0.4),\n",
        "\n",
        "        Bidirectional(LSTM(64, return_sequences=True)),\n",
        "        Dropout(0.4),\n",
        "\n",
        "        Bidirectional(LSTM(32)),\n",
        "        Dropout(0.4),\n",
        "\n",
        "        # Dense layers\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(0.4),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.4),\n",
        "\n",
        "        # Output layer\n",
        "        Dense(output_features, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss='mse',\n",
        "        metrics=['mae']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def train_improved_model(X, y, game_type):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    model = create_improved_model(X.shape[1], X.shape[2], y.shape[1])\n",
        "\n",
        "    callbacks = [\n",
        "        EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True),\n",
        "        ModelCheckpoint(f'improved_model_{game_type}.keras', save_best_only=True),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=0.0001)\n",
        "    ]\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=300,\n",
        "        batch_size=32,\n",
        "        validation_split=0.2,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    return model, history\n",
        "\n",
        "# Main execution for improved model\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Processing data with improved features...\")\n",
        "    (X_A, y_A, scaler_A), (X_P, y_P, scaler_P) = prepare_improved_data(\"2024.csv\")\n",
        "\n",
        "    print(\"Training improved model A...\")\n",
        "    model_A, history_A = train_improved_model(X_A, y_A, 'A')\n",
        "\n",
        "    print(\"Training improved model P...\")\n",
        "    model_P, history_P = train_improved_model(X_P, y_P, 'P')\n",
        "\n",
        "    # Make predictions and analyze results\n",
        "    #print(\"Analyzing results...\")\n",
        "\n",
        "    #analyze_predictions(model_A, X_A, scaler_A, 'A', y_A)\n",
        "    #analyze_predictions(model_P, X_P, scaler_P, 'P', y_P)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yVmuOrfLcac5",
        "outputId": "942ffe28-8b6e-4f5c-dd41-46a5d6dbf853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing data with improved features...\n",
            "Training improved model A...\n",
            "Epoch 1/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 148ms/step - loss: 0.0654 - mae: 0.2151 - val_loss: 0.0737 - val_mae: 0.2342 - learning_rate: 0.0010\n",
            "Epoch 2/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0610 - mae: 0.2073 - val_loss: 0.0580 - val_mae: 0.2034 - learning_rate: 0.0010\n",
            "Epoch 3/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0442 - mae: 0.1741 - val_loss: 0.0468 - val_mae: 0.1605 - learning_rate: 0.0010\n",
            "Epoch 4/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0379 - mae: 0.1520 - val_loss: 0.0437 - val_mae: 0.1612 - learning_rate: 0.0010\n",
            "Epoch 5/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0352 - mae: 0.1527 - val_loss: 0.0463 - val_mae: 0.1743 - learning_rate: 0.0010\n",
            "Epoch 6/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0347 - mae: 0.1526 - val_loss: 0.0438 - val_mae: 0.1615 - learning_rate: 0.0010\n",
            "Epoch 7/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0334 - mae: 0.1455 - val_loss: 0.0435 - val_mae: 0.1579 - learning_rate: 0.0010\n",
            "Epoch 8/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0370 - mae: 0.1531 - val_loss: 0.0437 - val_mae: 0.1624 - learning_rate: 0.0010\n",
            "Epoch 9/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0342 - mae: 0.1505 - val_loss: 0.0434 - val_mae: 0.1601 - learning_rate: 0.0010\n",
            "Epoch 10/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0341 - mae: 0.1486 - val_loss: 0.0433 - val_mae: 0.1589 - learning_rate: 0.0010\n",
            "Epoch 11/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0334 - mae: 0.1472 - val_loss: 0.0435 - val_mae: 0.1613 - learning_rate: 0.0010\n",
            "Epoch 12/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0336 - mae: 0.1463 - val_loss: 0.0435 - val_mae: 0.1613 - learning_rate: 0.0010\n",
            "Epoch 13/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0324 - mae: 0.1434 - val_loss: 0.0433 - val_mae: 0.1580 - learning_rate: 0.0010\n",
            "Epoch 14/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0341 - mae: 0.1460 - val_loss: 0.0434 - val_mae: 0.1599 - learning_rate: 0.0010\n",
            "Epoch 15/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0340 - mae: 0.1485 - val_loss: 0.0435 - val_mae: 0.1610 - learning_rate: 0.0010\n",
            "Epoch 16/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0324 - mae: 0.1437 - val_loss: 0.0436 - val_mae: 0.1611 - learning_rate: 0.0010\n",
            "Epoch 17/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0317 - mae: 0.1419 - val_loss: 0.0434 - val_mae: 0.1594 - learning_rate: 0.0010\n",
            "Epoch 18/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0372 - mae: 0.1539 - val_loss: 0.0435 - val_mae: 0.1607 - learning_rate: 0.0010\n",
            "Epoch 19/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0310 - mae: 0.1414 - val_loss: 0.0433 - val_mae: 0.1582 - learning_rate: 0.0010\n",
            "Epoch 20/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0341 - mae: 0.1459 - val_loss: 0.0434 - val_mae: 0.1603 - learning_rate: 0.0010\n",
            "Epoch 21/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0337 - mae: 0.1465 - val_loss: 0.0435 - val_mae: 0.1610 - learning_rate: 5.0000e-04\n",
            "Epoch 22/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0296 - mae: 0.1376 - val_loss: 0.0433 - val_mae: 0.1593 - learning_rate: 5.0000e-04\n",
            "Epoch 23/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0317 - mae: 0.1423 - val_loss: 0.0433 - val_mae: 0.1584 - learning_rate: 5.0000e-04\n",
            "Epoch 24/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0319 - mae: 0.1430 - val_loss: 0.0432 - val_mae: 0.1580 - learning_rate: 5.0000e-04\n",
            "Epoch 25/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0323 - mae: 0.1428 - val_loss: 0.0433 - val_mae: 0.1587 - learning_rate: 5.0000e-04\n",
            "Epoch 26/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0338 - mae: 0.1467 - val_loss: 0.0434 - val_mae: 0.1601 - learning_rate: 5.0000e-04\n",
            "Epoch 27/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0303 - mae: 0.1400 - val_loss: 0.0434 - val_mae: 0.1603 - learning_rate: 5.0000e-04\n",
            "Epoch 28/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0339 - mae: 0.1456 - val_loss: 0.0433 - val_mae: 0.1587 - learning_rate: 5.0000e-04\n",
            "Epoch 29/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0310 - mae: 0.1394 - val_loss: 0.0434 - val_mae: 0.1598 - learning_rate: 5.0000e-04\n",
            "Epoch 30/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0318 - mae: 0.1433 - val_loss: 0.0434 - val_mae: 0.1594 - learning_rate: 5.0000e-04\n",
            "Epoch 31/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0325 - mae: 0.1450 - val_loss: 0.0434 - val_mae: 0.1593 - learning_rate: 2.5000e-04\n",
            "Epoch 32/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0344 - mae: 0.1473 - val_loss: 0.0434 - val_mae: 0.1593 - learning_rate: 2.5000e-04\n",
            "Epoch 33/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0341 - mae: 0.1468 - val_loss: 0.0434 - val_mae: 0.1591 - learning_rate: 2.5000e-04\n",
            "Epoch 34/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0317 - mae: 0.1429 - val_loss: 0.0434 - val_mae: 0.1589 - learning_rate: 2.5000e-04\n",
            "Epoch 35/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0312 - mae: 0.1422 - val_loss: 0.0434 - val_mae: 0.1589 - learning_rate: 2.5000e-04\n",
            "Epoch 36/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0334 - mae: 0.1471 - val_loss: 0.0434 - val_mae: 0.1593 - learning_rate: 2.5000e-04\n",
            "Epoch 37/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0312 - mae: 0.1416 - val_loss: 0.0434 - val_mae: 0.1592 - learning_rate: 2.5000e-04\n",
            "Epoch 38/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0309 - mae: 0.1410 - val_loss: 0.0433 - val_mae: 0.1585 - learning_rate: 2.5000e-04\n",
            "Epoch 39/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0330 - mae: 0.1453 - val_loss: 0.0434 - val_mae: 0.1588 - learning_rate: 2.5000e-04\n",
            "Epoch 40/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0301 - mae: 0.1389 - val_loss: 0.0434 - val_mae: 0.1586 - learning_rate: 2.5000e-04\n",
            "Epoch 41/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0318 - mae: 0.1423 - val_loss: 0.0434 - val_mae: 0.1591 - learning_rate: 1.2500e-04\n",
            "Epoch 42/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0321 - mae: 0.1441 - val_loss: 0.0434 - val_mae: 0.1591 - learning_rate: 1.2500e-04\n",
            "Epoch 43/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0296 - mae: 0.1377 - val_loss: 0.0434 - val_mae: 0.1591 - learning_rate: 1.2500e-04\n",
            "Epoch 44/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0322 - mae: 0.1434 - val_loss: 0.0434 - val_mae: 0.1587 - learning_rate: 1.2500e-04\n",
            "Epoch 45/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0324 - mae: 0.1447 - val_loss: 0.0434 - val_mae: 0.1588 - learning_rate: 1.2500e-04\n",
            "Epoch 46/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0301 - mae: 0.1386 - val_loss: 0.0434 - val_mae: 0.1589 - learning_rate: 1.2500e-04\n",
            "Epoch 47/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0328 - mae: 0.1443 - val_loss: 0.0434 - val_mae: 0.1589 - learning_rate: 1.2500e-04\n",
            "Epoch 48/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0321 - mae: 0.1433 - val_loss: 0.0434 - val_mae: 0.1586 - learning_rate: 1.2500e-04\n",
            "Epoch 49/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0309 - mae: 0.1408 - val_loss: 0.0434 - val_mae: 0.1587 - learning_rate: 1.2500e-04\n",
            "Epoch 50/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0304 - mae: 0.1386 - val_loss: 0.0434 - val_mae: 0.1586 - learning_rate: 1.2500e-04\n",
            "Epoch 51/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0313 - mae: 0.1422 - val_loss: 0.0434 - val_mae: 0.1592 - learning_rate: 1.0000e-04\n",
            "Epoch 52/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0325 - mae: 0.1437 - val_loss: 0.0434 - val_mae: 0.1591 - learning_rate: 1.0000e-04\n",
            "Epoch 53/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0323 - mae: 0.1438 - val_loss: 0.0434 - val_mae: 0.1591 - learning_rate: 1.0000e-04\n",
            "Epoch 54/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0321 - mae: 0.1439 - val_loss: 0.0434 - val_mae: 0.1591 - learning_rate: 1.0000e-04\n",
            "Training improved model P...\n",
            "Epoch 1/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 149ms/step - loss: 0.0631 - mae: 0.2096 - val_loss: 0.0707 - val_mae: 0.2268 - learning_rate: 0.0010\n",
            "Epoch 2/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0546 - mae: 0.1940 - val_loss: 0.0559 - val_mae: 0.1957 - learning_rate: 0.0010\n",
            "Epoch 3/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0425 - mae: 0.1668 - val_loss: 0.0501 - val_mae: 0.1748 - learning_rate: 0.0010\n",
            "Epoch 4/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0423 - mae: 0.1643 - val_loss: 0.0487 - val_mae: 0.1801 - learning_rate: 0.0010\n",
            "Epoch 5/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0374 - mae: 0.1573 - val_loss: 0.0467 - val_mae: 0.1739 - learning_rate: 0.0010\n",
            "Epoch 6/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0399 - mae: 0.1596 - val_loss: 0.0456 - val_mae: 0.1680 - learning_rate: 0.0010\n",
            "Epoch 7/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0378 - mae: 0.1531 - val_loss: 0.0463 - val_mae: 0.1711 - learning_rate: 0.0010\n",
            "Epoch 8/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0387 - mae: 0.1581 - val_loss: 0.0470 - val_mae: 0.1739 - learning_rate: 0.0010\n",
            "Epoch 9/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0360 - mae: 0.1531 - val_loss: 0.0465 - val_mae: 0.1713 - learning_rate: 0.0010\n",
            "Epoch 10/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0366 - mae: 0.1538 - val_loss: 0.0462 - val_mae: 0.1693 - learning_rate: 0.0010\n",
            "Epoch 11/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0368 - mae: 0.1513 - val_loss: 0.0460 - val_mae: 0.1696 - learning_rate: 0.0010\n",
            "Epoch 12/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0372 - mae: 0.1541 - val_loss: 0.0459 - val_mae: 0.1684 - learning_rate: 0.0010\n",
            "Epoch 13/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0346 - mae: 0.1476 - val_loss: 0.0459 - val_mae: 0.1685 - learning_rate: 0.0010\n",
            "Epoch 14/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0359 - mae: 0.1509 - val_loss: 0.0463 - val_mae: 0.1705 - learning_rate: 0.0010\n",
            "Epoch 15/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0352 - mae: 0.1497 - val_loss: 0.0461 - val_mae: 0.1687 - learning_rate: 0.0010\n",
            "Epoch 16/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0363 - mae: 0.1512 - val_loss: 0.0459 - val_mae: 0.1680 - learning_rate: 0.0010\n",
            "Epoch 17/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0357 - mae: 0.1503 - val_loss: 0.0459 - val_mae: 0.1682 - learning_rate: 5.0000e-04\n",
            "Epoch 18/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0354 - mae: 0.1510 - val_loss: 0.0460 - val_mae: 0.1694 - learning_rate: 5.0000e-04\n",
            "Epoch 19/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0344 - mae: 0.1459 - val_loss: 0.0460 - val_mae: 0.1686 - learning_rate: 5.0000e-04\n",
            "Epoch 20/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0361 - mae: 0.1520 - val_loss: 0.0462 - val_mae: 0.1702 - learning_rate: 5.0000e-04\n",
            "Epoch 21/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0355 - mae: 0.1494 - val_loss: 0.0461 - val_mae: 0.1700 - learning_rate: 5.0000e-04\n",
            "Epoch 22/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0344 - mae: 0.1472 - val_loss: 0.0459 - val_mae: 0.1673 - learning_rate: 5.0000e-04\n",
            "Epoch 23/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0336 - mae: 0.1439 - val_loss: 0.0459 - val_mae: 0.1682 - learning_rate: 5.0000e-04\n",
            "Epoch 24/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0340 - mae: 0.1481 - val_loss: 0.0458 - val_mae: 0.1681 - learning_rate: 5.0000e-04\n",
            "Epoch 25/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0374 - mae: 0.1540 - val_loss: 0.0459 - val_mae: 0.1687 - learning_rate: 5.0000e-04\n",
            "Epoch 26/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0337 - mae: 0.1475 - val_loss: 0.0458 - val_mae: 0.1671 - learning_rate: 5.0000e-04\n",
            "Epoch 27/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0369 - mae: 0.1531 - val_loss: 0.0457 - val_mae: 0.1669 - learning_rate: 2.5000e-04\n",
            "Epoch 28/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0373 - mae: 0.1524 - val_loss: 0.0458 - val_mae: 0.1678 - learning_rate: 2.5000e-04\n",
            "Epoch 29/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0354 - mae: 0.1508 - val_loss: 0.0458 - val_mae: 0.1683 - learning_rate: 2.5000e-04\n",
            "Epoch 30/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0348 - mae: 0.1487 - val_loss: 0.0459 - val_mae: 0.1684 - learning_rate: 2.5000e-04\n",
            "Epoch 31/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0343 - mae: 0.1480 - val_loss: 0.0459 - val_mae: 0.1686 - learning_rate: 2.5000e-04\n",
            "Epoch 32/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0355 - mae: 0.1498 - val_loss: 0.0458 - val_mae: 0.1682 - learning_rate: 2.5000e-04\n",
            "Epoch 33/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0337 - mae: 0.1466 - val_loss: 0.0458 - val_mae: 0.1674 - learning_rate: 2.5000e-04\n",
            "Epoch 34/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0329 - mae: 0.1442 - val_loss: 0.0458 - val_mae: 0.1675 - learning_rate: 2.5000e-04\n",
            "Epoch 35/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0349 - mae: 0.1487 - val_loss: 0.0458 - val_mae: 0.1681 - learning_rate: 2.5000e-04\n",
            "Epoch 36/300\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0357 - mae: 0.1513 - val_loss: 0.0458 - val_mae: 0.1677 - learning_rate: 2.5000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "\n",
        "# Make predictions and analyze results\n",
        "print(\"Analyzing results...\")\n",
        "\n",
        "# Make predictions for next games\n",
        "print(\"Making predictions...\")\n",
        "last_sequence_A = X_A[-1:]\n",
        "last_sequence_P = X_P[-1:]\n",
        "\n",
        "print(\"Predicting next 'A' game numbers...\")\n",
        "print(\"Predicting next 'P' game numbers...\")\n",
        "\n",
        "predictions_A = model_A.predict(last_sequence_A)\n",
        "top_10_predictions_A = process_predictions(predictions_A, scaler_A, original_features_count=10, top_n=10)\n",
        "\n",
        "predictions_P = model_P.predict(last_sequence_P)\n",
        "top_10_predictions_P = process_predictions(predictions_P, scaler_P, original_features_count=10, top_n=10)\n",
        "\n",
        "display_predictions(top_10_predictions_A, 'A')\n",
        "display_predictions(top_10_predictions_P, 'P')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "O-PAnhEcd27L",
        "outputId": "b2235bf9-b9c3-48e3-fe5c-0422323229d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing results...\n",
            "Making predictions...\n",
            "Predicting next 'A' game numbers...\n",
            "Predicting next 'P' game numbers...\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\n",
            "Sorted pairs (number, confidence): [(19, 67.30063), (18, 63.95086), (17, 60.706852), (16, 57.375664), (15, 54.109886), (14, 50.715282), (13, 47.297832), (12, 43.827694), (11, 40.447495), (10, 36.954765), (9, 33.909683), (8, 30.642344), (7, 27.690271), (6, 24.018663), (5, 20.456509)]\n",
            "Top 10 indices: [19, 18, 17, 16, 15, 14, 13, 12, 11, 10]\n",
            "Final top 10 numbers: [37 40 44 47 51 54 57 61 64 67]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437ms/step\n",
            "\n",
            "Sorted pairs (number, confidence): [(19, 66.860695), (18, 63.593044), (17, 60.47284), (16, 57.694374), (15, 54.209644), (14, 50.24315), (13, 47.719685), (12, 44.555893), (11, 40.414143), (10, 37.85281), (9, 34.899616), (8, 31.538483), (7, 27.630959), (6, 24.703793), (5, 20.661854)]\n",
            "Top 10 indices: [19, 18, 17, 16, 15, 14, 13, 12, 11, 10]\n",
            "Final top 10 numbers: [38 40 45 48 50 54 58 60 64 67]\n",
            "\n",
            "Game Type: A\n",
            "Rank: 1\n",
            "Numbers: 37, 40, 44, 47, 51, 54, 57, 61, 64, 67\n",
            "Confidence Score: 52.27\n",
            "--------------------------------------------------\n",
            "\n",
            "Game Type: P\n",
            "Rank: 1\n",
            "Numbers: 38, 40, 45, 48, 50, 54, 58, 60, 64, 67\n",
            "Confidence Score: 52.36\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}